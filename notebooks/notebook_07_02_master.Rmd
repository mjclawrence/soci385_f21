---
title: "Introducing Hypothesis Testing"
date: "October 27, 2021"
author: "Matt Lawrence"
output:
  pdf_document: default
  html_notebook: default
---

## Setting Up

Load the `gss_week7.csv` file on Canvas as a data frame called `gss_week7` and load the usual packages:

```{r load data and packages, include = FALSE, warning = FALSE}
gss_week7 <- read.csv("https://raw.githubusercontent.com/mjclawrence/soci385/master/data/gss_week7.csv")
library(tidyverse)
library(pander)
```


## Comparing The Z and T Distributions

When the population standard deviation is unknown (almost always), the uncertainty of the standard error estimate is addressed by using a new distribution: the t distribution. This distribution also has a bell shape, but its tails are thicker than the normal modelâ€™s.

When the sample size is large, z and t are the same. When in doubt, use t. It will always work since it adjusts for the sample size.

You can find t-values and associated probabilities using functions similar to the `norm()` functions. The difference is that with the `t()` functions you also give the degrees of freedom.


This is what we did before to get the z-value associated with the 95% confidence interval:
```{r qnorm for normal distribution}
qnorm(.975) 
```

The equivalent code with the t-distribution and a sample size of 1001 (so df = 1000):
```{r qt for t distribution}
qt(.975, df = 1000)
```

With smaller samples, using the t-distribution builds in extra room since our estimates are less reliable: 
```{r qt for t distribution with smaller sample}
qt(.975, df = 100)
```

To find the probabilities associated with t-values, use `pt()` which also requires degrees of freedom:
```{r pt for t distribution}
pt(1.962339, df = 1000)
```

And 1 - pt() also works the same way as 1 - pnorm():
```{r pt for t distribution with smaller sample}
1 - pt(1.983972, df = 100)
```


## Significance Testing

Let's test if the mean value of `childs` in 2014 differed from 2.04 (the 1984 mean).

What was the mean for `childs` in 2014?

### REPLACE THIS LINE WITH YOUR CODE

```{r find mean for sample year}
mean(gss_week7$childs[gss_week7$year==2014])
```


The test statistic is calculated as: 
$\Large{t = \frac{y - y_{H0}}{SD/ \sqrt{n}}}$

For our test, the test statistic is:

```{r calculate test statistic}
(1.770325 - 2.04) / 0.05801424
```

What is the t-value for the critical region for our sample size and an alpha level of .05?

### REPLACE THIS LINE WITH YOUR CODE ###

```{r find t value for critical region}
qt(.025, df = 491)
```


## Shortcut!

R has a built-in function called `t.test()` that will calculate all of these test statistics. With one mean, we have to fill in the value of mu ($\mu$) which is the null hypothesis value. If you leave it out, the default is zero.

```{r t test in r}
t.test(gss_week7$childs[gss_week7$year==2014], mu = 2.04)
```

For another example, let's look at 2014's mean ideal number of children (variable = `ideal_childs`). Using `t.test()`, can we reject the null hypothesis that the 2014 mean is the same as 2.41 at the .05 alpha level?

### REPLACE THIS LINE WITH YOUR CODE

```{r t test in r exercise}
t.test(gss_week7$ideal_childs[gss_week7$year==2014], mu = 2.41)
```

Can we reject the null hypothesis that the 2014 mean is the same as 2.5 at the .01 alpha level? We can change the default level of .05 to .01 using the conf.level option (which requires the confidence level, so .99 for the .01 alpha level).

### REPLACE THIS LINE WITH YOUR CODE

```{r t test 2 in r exercise}
t.test(gss_week7$ideal_childs[gss_week7$year==2014], mu = 2.5,
       conf.level = .99)
```