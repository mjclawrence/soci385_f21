---
title: "Tests of Association"
date: "November 8, 2021"
author: "Matt Lawrence"
output:
  pdf_document: default
---

## Setting Up

We'll use the `week_9.csv` file today. Load it as a data frame called `week9` and load the usual packages:

```{r, include = FALSE, warning = FALSE}
week9 <- read.csv("https://raw.githubusercontent.com/mjclawrence/soci385_f21/main/data/week_9.csv")
library(tidyverse)
library(pander)
```

## Introducing Association

Two variables have a *dependent association* if knowing value of one variable helps predict value of the other variable. Two variables have an *independent association* if knowing value of one variable does not help predict value of the other variable.

We want to know if there is a statistically significant dependent association between geographic place and beliefs about whether courts deal too harshly or not harshly enough with criminals. Make a table (including the sums) with `region` in the rows and `courts` in the columns:

### REPLACE THIS LINE WITH YOUR CODE

```{r}
addmargins(table(week9$region, week9$courts))
```


We will use the chi-squared test of independence to test whether or not we can reject the null hypothesis that there is no association between the two variables. The test statistic is:

$\Large{x^2 = \sum {\frac {(f_o - f_e)^2} {f_e}}}$

To calculate the test statistic, we need the observed frequencies and the expected frequencies. We just saw the observed frequencies.

The expected value of each cell is defined as:
(total in row * total in column) / (total in table)

What is the expected value for the "Mid Atlantic, About right" cell?

```{r}
(985 * 1665) / 8516
```

Calculate the expected values for the other two columns in the first row:

### REPLACE THIS LINE WITH YOUR CODE

```{r}
# For Mid Atlantic, Not Harsh Enough:
(985 * 5426) / 8516

# For Mid Atlantic, Too Harsh:
(985 * 1425) / 8516
```

To do the chi-squared test by hand, we will need a table with all the expected frequencies. We just did the Mid Atlantic row; here are those frequencies saved as a vector, a separate vector for each additional region, and the code to make the table:

```{r}
expected_ma <- c(192.5816, 627.5963, 164.82210)
expected_mw <- c(683.1271, 2226.2147, 584.65829)
expected_ne <- c(86.0263, 280.3476, 73.62612)
expected_se <- c(335.3071, 1092.7184, 286.97452)
expected_we <- c(367.9580, 1199.1231, 314.91898)

expected_table <- rbind(expected_ma, expected_mw, 
                  expected_ne, expected_se, expected_we)

rownames(expected_table) <- c("Mid Atlantic", "Midwest", 
      "New England", "Southeast", "West")

colnames(expected_table) <- c("About right", 
      "Not harsh enough", "Too harsh")
```

Take a look at the table of expected values:

```{r}
expected_table
```

Let's also save the observed frequencies (without the marginals):

```{r}
observed_table <- table(week9$region, week9$courts)
```

The difference between each observed and expected value is the *residual*. Save all the residuals in a table called `residual_table`:

### REPLACE THIS LINE WITH YOUR CODE

```{r}
residual_table <- observed_table - expected_table
```

For each cell, square the residual and divide it by its expected frequency:

```{r}
chi2_table <- (residual_table^2)/expected_table
round(chi2_table, 3)
```

The test statistic is the sum of all the cells' chi-squared values:

```{r}
sum(chi2_table)

```

For this test, the degrees of freedom are calculated as:
(# of rows - 1)(# of columns - 1)

So in the regionsXcourts table, the degrees of freedom are...

### REPLACE THIS LINE WITH YOUR CODE

```{r}
(5-1) * (3-1)
```

To find the cutoff for the critical region, use `qchisq()` with the degrees of freedom:

```{r}
qchisq(.95, df = 8)
```

With DF=8, need a chi-square test statistic at least as big as 15.50731 to reject the null hypothesis. With our test statistic of 29.9, we can reject the null hypothesis that the two variables are independent. That means there is a significant association between them.

To convert the test statistic to a p-value, use 1 - pchisq() with the degrees of freedom:

```{r}
1 - pchisq(29.9, df = 8)
```


## Shortut in R

R can do all of this with the built-in `chisq.test()` function, which requires the two variable names (not a table):

```{r}
chisq.test(week9$region, week9$courts)
```

## Another example

Is there a significant association between `region` and `nateduc` (the variable for the question: "Are we spending too much on education")?

### REPLACE THIS LINE WITH YOUR CODE

```{r}
chisq.test(week9$region, week9$nateduc)
```

## More practice...

Test a pair of variables where you think there would be a significant association. Test a pair of variables where you do not think there would be a significant association.

```{r}
chisq.test(week9$sex, week9$abany)
```

```{r}
chisq.test(week9$class, week9$nateduc)
```

```{r}
qchisq(.95, df = 6)
```

```{r}
library(vcdExtra)
```

```{r}
gamma_table <- table(week9$class, week9$nateduc)
GKgamma(gamma_table)
```


```{r}
round(prop.table(table(week9$born, week9$courts),1),3)
```

```{r}
chisq.test(week9$born, week9$courts)
qchisq(.95, df = 2)
```

```{r}
round(prop.table(table(week9$born, week9$abany),1),3)
```

```{r}
chisq.test(week9$born, week9$abany)
qchisq(p = .95, 1)
```

```{r}
round(prop.table(table(week9$sex, week9$region),1),3)
```

```{r}
chisq.test(week9$sex, week9$region)
qchisq(p = .95, df = 4)
```

