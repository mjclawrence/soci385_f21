<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>Social Statistics</title>
    <meta charset="utf-8" />
    <meta name="date" content="2021-10-20" />
    <script src="libs/header-attrs/header-attrs.js"></script>
    <link href="libs/remark-css/default.css" rel="stylesheet" />
    <link href="libs/remark-css/metropolis-fonts.css" rel="stylesheet" />
    <link rel="stylesheet" href="metropolis.css" type="text/css" />
    <link rel="stylesheet" href="monofont.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">
class: middle, title-slide

# Social Statistics
## Sampling Distributions
### October 20, 2021

---




# Thinking Probabilistically

### So far: Summarizing observed values of variables
- Descriptions about the centers and shapes of distributions

--

### Now: Estimating probability of observing value in the sample
- Or, quantifying chance that a value is different from what is observed

--

### Up next: Inference
- What is the probability that a sample statistic is different from a population parameter?

---

# Thinking Probabilistically

### Using what we observe in our sample to estimate what we want to know about the population
- The population value exists but we don't observe it. We'll use what we do know to estimate the range of possible values for the population measure.

--

### From describing precision...
- 25% of commuting zones spend more than the national average on school expenditures

--

### To quantifying likelihood...
- 2.5% chance that a commuting zone we randomly pull from the data set will spend more than Addison County does on school expenditures

---

# Thinking Probabilistically

### For now, assume variable is normally distributed, and apply what we know about means and standard deviations in normal distributions...

---

# Normal Distribution

![](385_figures/normal.png)

---

# Back to R

### Strategy with probability distributions is to find a value's distance from the mean in standard deviations. This measure is called the `z-score`.

--

### `\(\Large{z = \frac{x - \mu}{\sigma}}\)`

--

### Positive z-score is a value's distance above the mean in standard deviations

### Negative z-score is a value's distance below the mean in standard deviations

---

# Example With OK Cupid Dataset

![](slides_06_01_files/figure-html/unnamed-chunk-1-1.png)&lt;!-- --&gt;

---

# Calculating Z Scores

### For each observation, we need to find the difference from the mean and then divide that difference by the standard deviation.

--



```r
cupid &lt;- mutate(cupid, height_z = 
                  (height - mean(height)) /
                               sd(height))
```

---

# Calculating Z Scores

### Z-scores should be normally distributed with a mean of 0 and a standard deviation of 1. Were we successful?

--


```r
summary(cupid$height_z)
```

```
##     Min.  1st Qu.   Median     Mean  3rd Qu.     Max. 
## -2.92468 -0.86381 -0.09099  0.00000  0.68184  3.00031
```

```r
sd(cupid$height_z)
```

```
## [1] 1
```

---

# Interpreting Z-Scores

### What is the z-score for a height of 71 inches?

--


```r
mean(cupid$height_z[cupid$height==71])
```

```
## [1] 0.6818372
```

--

### In words, someone who is 71 inches tall is .68 standard deviations taller than the mean.

---

# Interpreting Z-Scores

### When we plot standardized values that are approximately normal, we now know a lot about how many observations fall along different points of the distribution

![:scale 100%](385_figures/normal.png)


---

# Interpreting Z-Scores

![](slides_06_01_files/figure-html/unnamed-chunk-5-1.png)&lt;!-- --&gt;


---

# Interpreting Z-Scores

### To find the probability that a randomly pulled observation will have a height of 71 inches, use `dnorm()`:

--


```r
dnorm(0.6818372) # d for density
```

```
## [1] 0.3161971
```

--

### More precisely, that's the probability a randomly pulled observation will have a height above 70 inches and below than 72 inches. Looks pretty close...


---

# Interpreting Z-Scores

![](slides_06_01_files/figure-html/unnamed-chunk-7-1.png)&lt;!-- --&gt;

---

# Cumulative Probabilities and Densities

![](slides_06_01_files/figure-html/unnamed-chunk-8-1.png)&lt;!-- --&gt;

---

# Cumulative Probabilities and Densities

### To find the area under the curve, we need to know the `cumulative density` not the density. The cumulative density is the same as the percentile.

--

### If you have the z-value and want the percentile associated with it, use `pnorm()` which gives you the proportion of the distribution to the left of your z-value.

--

### For Height of 71 Inches:


```r
pnorm(.6818372) # p for percentile
```

```
## [1] 0.7523291
```

---

# Cumulative Probabilities and Densities

![](slides_06_01_files/figure-html/unnamed-chunk-10-1.png)&lt;!-- --&gt;

---

# Use What You Know


### What is the probability of another respondent being taller than 71 inches?

--


```r
1 - pnorm(.682)
```

```
## [1] 0.2476195
```

---

# Use What You Know

![](slides_06_01_files/figure-html/unnamed-chunk-11-1.png)&lt;!-- --&gt;

---

# Exercise

### What is the z-score for 64 inches?

### What is the probability that someone in our sample is shorter and taller than 64 inches?

---

# Exercise

### What is the z-score for 64 inches?

--


```r
mean(cupid$height_z[cupid$height==64])
```

```
## [1] -1.12142
```

--

### What is probability that someone in our sample is shorter than 64 inches?

--


```r
pnorm(-1.12)
```

```
## [1] 0.1313569
```

--

### What is the probability that someone in our sample is taller than 64 inches?

--


```r
1 - pnorm(-1.12)
```

```
## [1] 0.8686431
```

---

# What's the point?

--

### The key bridge to inference is thinking of the x-axis not as observed values of height in our sample but as possible values of the true mean of height in the population.

--


### We want to know how close the mean in our observed sample is to the true (unobserved) population mean. Knowing where it falls in the distribution of all the possible sample means is how we infer how similar the sample mean and the population are.

--

### Remember our new language: what is the probability of another randomly drawn sample mean being more extreme than our sample mean *simply by chance*.

---

# Measuring Sampling Variation

### Bootstrapping is one approach. It gives us repeated samples of our sample so we have more possible values of our statistic.

--

### That is helpful because as sample size increases, distribution of z-values of repeated sample means is normally distributed around standardized population mean of 0 with a standard deviation of 1.

--

### That's the key insight: since the means from repeated samples are normally distributed, now it is not a problem if the distribution in one sample is not normally distributed. If our sample size is big enough, we can think of our observed values as possible estimates of the population mean!

---

# Measuring Sampling Variation

### We won't use bootstrapping to pull repeated samples. But we'll use the *standard deviation* of our sample to calculate the *standard error* of the sampling distribution.

--

### `\(\Large{\sigma_{\bar{y}} = \frac{\sigma}{\sqrt{n}} = \frac{sd}{\sqrt{sample size}}}\)`

---


# An Example

### In the `cupid` data set, the age variable is *not* normally distributed, but we still want to use probability to estimate the population mean from our sample mean.

--

### Let's find the standard error of the age variable. We'll save this as an object, not as a new variable (since it is the same for the entire sample):

--


```r
age_se &lt;- sd(cupid$age) / sqrt(length(cupid$age))

age_se
```

```
## [1] 0.1847327
```

---

# From SE To Confidence Intervals

### We use the standard error, the sample mean and what we know about the distribution of z-scores to build a range of possible values for the population mean

--

### The most common range is a *95% confidence interval*
- That is the range in which the true population mean will be found in 95% of sampling distributions
- We are ***not*** saying we are 95% sure that our sample mean is the population mean!

---

# From SE To Confidence Intervals

### To build that 95% interval, we need to define a range that captures 95% of the normal distribution. In other words, outside this range there will be only a 2.5% chance that another sample will have a mean above our mean and a 2.5% chance that another sample will have a mean below our mean.

--

### That should sound like z-scores!

---

# From SE To Confidence Intervals

### We need the z-scores that are associated with .025 and .975. To find them, we use `qnorm()`.

--


```r
qnorm(.025)
```

```
## [1] -1.959964
```

```r
qnorm(.975)
```

```
## [1] 1.959964
```

---

# Z-Scores For Confidence Intervals

## 95% (most common) = 1.96

## 99% = 2.58

## 90% (less common) = 1.65

---

# From SE To Confidence Intervals

### The z-score for the confidence level we want multiplied by our standard error is the *margin of error*

--


```r
# Margin of Error:

1.96*age_se
```

```
## [1] 0.3620762
```


---

# From SE To Confidence Intervals

### Our sample mean plus and minus the margin of error is our confidence interval

--

### Find both the *lower limit* and the *upper limit*

--


```r
# Lower Limit of Confidence Interval
age_ll &lt;- mean(cupid$age) - 1.96*age_se

# Upper Limit of Confidence Interval
age_ul &lt;- mean(cupid$age) + 1.96*age_se
```

---

# From SE To Confidence Intervals

### Often helpful to save the lower limit, mean, and upper limit as a vector

--


```r
age_ci &lt;- c(age_ll, mean(cupid$age), age_ul)

age_ci
```

```
## [1] 32.02192 32.38400 32.74608
```

--

### Interpretation?
- 95% of the repeated samples we might imagine pulling would be expected to have means within this range, giving us 95% confidence that the true population mean falls within this range

---

# Exercise

## What is the 99% confidence interval for height?

### Find the standard error

### Find the margin of error

### Construct the confidence interval

---

# Exercise


```r
# Find the standard error:

height_se &lt;- sd(cupid$height) / sqrt(length(cupid$height))
```

--


```r
# For the margin of error, we need .005 on each side of our mean:

qnorm(.995)
```

```
## [1] 2.575829
```

--


```r
# Margin of error =

2.58 * height_se
```

```
## [1] 0.2003042
```

---

# Exercise


```r
# Construct the 99% Confidence Interval

height_ll &lt;- mean(cupid$height) - 2.58*height_se
height_ul &lt;- mean(cupid$height) + 2.58*height_se

height_ci &lt;- c(height_ll, mean(cupid$height), height_ul)
```

--


```r
# Display

height_ci
```

```
## [1] 68.1529 68.3532 68.5535
```

--

### Interpretation?
    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script src="macros.js"></script>
<script>var slideshow = remark.create({
"highlightLines": true,
"highlightStyle": "zenburn",
"highlightSpans": true
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
